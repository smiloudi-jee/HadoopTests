# --- Configuration Générale MiniDFS ---
hadoop.hdfs.home=minicluster-work
advertisedhost=localhost
hadoop.host=192.168.1.50
nn.rpc.port=20112
nn.http.port=9870
dn.http.port=9864
dn.xfer.port=9866
dn.ipc.port=9867

dfs.permissions.enabled=false
fs.permissions.umask-mode=000

#Configurations spécifiques pour le binding des adresses IP/hostnames
dfs.namenode.rpc-bind-host=0.0.0.0
dfs.namenode.http-bind-host=0.0.0.0
dfs.datanode.bind-host=0.0.0.0

#Important quand les clients sont sur d'autres machines/sous-réseaux
dfs.client.use.datanode.hostname=true

# Spark/Hive
app.spark.hive.name=MiniSparkHive
spark.enabled=true
sparkHive.enabled=true
hive.warehouse.dir=/user/hive/warehouse
spark.master=local[*]
spark.sql.warehouse.dir=hdfs:///user/hive/warehouse

# Nettoyage du metastore Derby au démarrage (utile en tests)
metastore.cleanOnStart=false

# Hive Metastore
javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=metastore_db;create=true
datanucleus.autoCreateSchema=true
hive.metastore.schema.verification=false
spark.sql.catalogImplementation=hive
spark.log.level=WARN
spark.hadoop.dfs.client.use.datanode.hostname=true

# Exposition REST
rest.enabled=true
rest.port=18080
rest.cors=*

# Thrift Server (JDBC)
thrift.enabled=true
thrift.port=10000
